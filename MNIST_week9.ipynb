{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1mZfAh5Rj0pFiPaVZunaJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avisruti/AI-ML/blob/main/MNIST_week9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AQ2F134TJHos"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_subset(full_train_set, full_test_set, label_one, label_two):\n",
        "    # Sample the correct train labels\n",
        "    train_set = []\n",
        "    data_lim = 20000\n",
        "    for data in full_train_set:\n",
        "        if data_lim>0:\n",
        "            data_lim-=1\n",
        "            if data[1]==label_one or data[1]==label_two:\n",
        "                train_set.append(data)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    test_set = []\n",
        "    data_lim = 1000\n",
        "    for data in full_test_set:\n",
        "        if data_lim>0:\n",
        "            data_lim-=1\n",
        "            if data[1]==label_one or data[1]==label_two:\n",
        "                test_set.append(data)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return train_set, test_set"
      ],
      "metadata": {
        "id": "-sEwPSBYLY0H"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,optimizer,train_loader,epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        data, target = Variable(data), Variable(target)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "3LgJ0WL8LkKh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model,test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        if torch.cuda.is_available():\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        with torch.no_grad():\n",
        "            data, target = Variable(data), Variable(target)\n",
        "        output = model(data)\n",
        "        test_loss += F.cross_entropy(output, target, reduction='sum').item()#size_average=False\n",
        "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    acc=100. * float(correct.to(torch.device('cpu')).numpy())\n",
        "    test_accuracy = (acc / len(test_loader.dataset))\n",
        "    return test_accuracy"
      ],
      "metadata": {
        "id": "I-2pa_OPLpek"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num=10):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.feature = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding=1), # 28x28 -> 26x26\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1), # 26x26 -> 26x26\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # 26x26 -> 13x13\n",
        "            nn.Conv2d(in_channels=64, out_channels=96, kernel_size=3, stride=1, padding=1), # 13x13 -> 13x13\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=96, out_channels=64, kernel_size=3, stride=1, padding=1), # 13x13 -> 13x13\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=1), # 13x13 -> 13x13\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=1)  # 13x13 -> 12x12\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(32 * 12 * 12, 2048),  # 32 channels * 12x12 feature map size\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, num)  # Output layer, num features = 10\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "9CnR254jMCdb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    input_data_one = 8\n",
        "    input_data_two = 7\n",
        "    epochs = 5\n",
        "\n",
        "    \"\"\"  Call to function that will perform the computation. \"\"\"\n",
        "    #if input_data_one.isdigit() and input_data_two.isdigit() and epochs.isdigit():\n",
        "\n",
        "    label_one = int(input_data_one)\n",
        "    label_two = int(input_data_two)\n",
        "    epochs = int(epochs)\n",
        "\n",
        "    if label_one!=label_two and 0<=label_one<=9 and 0<=label_two<=9:\n",
        "            torch.manual_seed(42)\n",
        "            # Load MNIST dataset\n",
        "            trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
        "            full_train_set = dset.MNIST(root='./data', train=True, transform=trans, download=True)\n",
        "            full_test_set = dset.MNIST(root='./data', train=False, transform=trans)\n",
        "            batch_size = 16\n",
        "            # Get final train and test sets\n",
        "            train_set, test_set = load_subset(full_train_set,full_test_set,label_one,label_two)\n",
        "\n",
        "            train_loader = torch.utils.data.DataLoader(dataset=train_set,batch_size=batch_size,shuffle=False)\n",
        "            test_loader = torch.utils.data.DataLoader(dataset=test_set,batch_size=batch_size,shuffle=False)\n",
        "\n",
        "            model = AlexNet()\n",
        "            if torch.cuda.is_available():\n",
        "                model.cuda()\n",
        "\n",
        "            optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "            for epoch in range(1, epochs+1):\n",
        "                train(model,optimizer,train_loader,epoch)\n",
        "                accuracy = test(model,test_loader)\n",
        "\n",
        "            print(round(accuracy,2))\n",
        "\n",
        "\n",
        "    else:\n",
        "           print(\"Invalid input\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxjjCYmXMH6j",
        "outputId": "05f707e2-44e1-4221-e4ba-c41539adc577"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95.21\n"
          ]
        }
      ]
    }
  ]
}